<div class="announce instapaper_body md" data-path="README.md" id="readme"><article class="markdown-body entry-content" itemprop="mainContentOfPage"><h1>
<a name="user-content-twemproxy-nutcracker-" class="anchor" href="#twemproxy-nutcracker-" aria-hidden="true"><span class="octicon octicon-link"></span></a>twemproxy (nutcracker) <a href="http://travis-ci.org/twitter/twemproxy"><img src="https://camo.githubusercontent.com/eff0a460e8db9805b15291f0f172dce93a9fb685/68747470733a2f2f7365637572652e7472617669732d63692e6f72672f747769747465722f7477656d70726f78792e706e67" alt="Build Status" data-canonical-src="https://secure.travis-ci.org/twitter/twemproxy.png" style="max-width:100%;"></a>
</h1>

<p><strong>twemproxy</strong> (pronounced "two-em-proxy"), aka <strong>nutcracker</strong> is a fast and lightweight proxy for <a href="http://www.memcached.org/">memcached</a> and <a href="http://redis.io/">redis</a> protocol. It was primarily built to reduce the connection count on the backend caching servers.</p>

<h2>
<a name="user-content-build" class="anchor" href="#build" aria-hidden="true"><span class="octicon octicon-link"></span></a>Build</h2>

<p>To build nutcracker from <a href="http://code.google.com/p/twemproxy/downloads/list">distribution tarball</a>:</p>

<pre><code>$ ./configure
$ make
$ sudo make install
</code></pre>

<p>To build nutcracker from <a href="http://code.google.com/p/twemproxy/downloads/list">distribution tarball</a> in <em>debug mode</em>:</p>

<pre><code>$ CFLAGS="-ggdb3 -O0" ./configure --enable-debug=full
$ make
$ sudo make install
</code></pre>

<p>To build nutcracker from source with <em>debug logs enabled</em> and <em>assertions disabled</em>:</p>

<pre><code>$ git clone git@github.com:twitter/twemproxy.git
$ cd twemproxy
$ autoreconf -fvi
$ ./configure --enable-debug=log
$ make
$ src/nutcracker -h
</code></pre>

<h2>
<a name="user-content-features" class="anchor" href="#features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Features</h2>

<ul class="task-list">
<li>Fast.</li>
<li>Lightweight.</li>
<li>Maintains persistent server connections.</li>
<li>Keeps connection count on the backend caching servers low.</li>
<li>Enables pipelining of requests and responses.</li>
<li>Supports proxying to multiple servers.</li>
<li>Supports multiple server pools simultaneously.</li>
<li>Shard data automatically across multiple servers.</li>
<li>Implements the complete <a href="notes/memcache.txt">memcached ascii</a> and <a href="notes/redis.md">redis</a> protocol.</li>
<li>Easy configuration of server pools through a YAML file.</li>
<li>Supports multiple hashing modes including consistent hashing and distribution.</li>
<li>Can be configured to disable nodes on failures.</li>
<li>Observability through stats exposed on stats monitoring port.</li>
<li>Works with Linux, *BSD, OS X and Solaris (SmartOS)</li>
</ul><h2>
<a name="user-content-help" class="anchor" href="#help" aria-hidden="true"><span class="octicon octicon-link"></span></a>Help</h2>

<pre><code>Usage: nutcracker [-?hVdDt] [-v verbosity level] [-o output file]
                  [-c conf file] [-s stats port] [-a stats addr]
                  [-i stats interval] [-p pid file] [-m mbuf size]

Options:
  -h, --help             : this help
  -V, --version          : show version and exit
  -t, --test-conf        : test configuration for syntax errors and exit
  -d, --daemonize        : run as a daemon
  -D, --describe-stats   : print stats description and exit
  -v, --verbosity=N      : set logging level (default: 5, min: 0, max: 11)
  -o, --output=S         : set logging file (default: stderr)
  -c, --conf-file=S      : set configuration file (default: conf/nutcracker.yml)
  -s, --stats-port=N     : set stats monitoring port (default: 22222)
  -a, --stats-addr=S     : set stats monitoring ip (default: 0.0.0.0)
  -i, --stats-interval=N : set stats aggregation interval in msec (default: 30000 msec)
  -p, --pid-file=S       : set pid file (default: off)
  -m, --mbuf-size=N      : set size of mbuf chunk in bytes (default: 16384 bytes)
</code></pre>

<h2>
<a name="user-content-zero-copy" class="anchor" href="#zero-copy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zero Copy</h2>

<p>In nutcracker, all the memory for incoming requests and outgoing responses is allocated in mbuf. Mbuf enables zero-copy because the same buffer on which a request was received from the client is used for forwarding it to the server. Similarly the same mbuf on which a response was received from the server is used for forwarding it to the client.</p>

<p>Furthermore, memory for mbufs is managed using a reuse pool. This means that once mbuf is allocated, it is not deallocated, but just put back into the reuse pool. By default each mbuf chunk is set to 16K bytes in size. There is a trade-off between the mbuf size and number of concurrent connections nutcracker can support. A large mbuf size reduces the number of read syscalls made by nutcracker when reading requests or responses. However, with large mbuf size, every active connection would use up 16K bytes of buffer which might be an issue when nutcracker is handling large number of concurrent connections from clients. When nutcracker is meant to handle a large number of concurrent client connections, you should set chunk size to a small value like 512 bytes using the -m or --mbuf-size=N argument.</p>

<h2>
<a name="user-content-configuration" class="anchor" href="#configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Configuration</h2>

<p>nutcracker can be configured through a YAML file specified by the -c or --conf-file command-line argument on process start. The configuration file is used to specify the server pools and the servers within each pool that nutcracker manages. The configuration files parses and understands the following keys:</p>

<ul class="task-list">
<li>
<strong>listen</strong>: The listening address and port (name:port or ip:port) for this server pool.</li>
<li>
<strong>hash</strong>: The name of the hash function. Possible values are:

<ul class="task-list">
<li>one_at_a_time</li>
<li>md5</li>
<li>crc16</li>
<li>crc32 (crc32 implementation compatible with <a href="http://libmemcached.org/">libmemcached</a>)</li>
<li>crc32a (correct crc32 implementation as per the spec)</li>
<li>fnv1_64</li>
<li>fnv1a_64</li>
<li>fnv1_32</li>
<li>fnv1a_32</li>
<li>hsieh</li>
<li>murmur</li>
<li>jenkins</li>
</ul>
</li>
<li>
<strong>hash_tag</strong>: A two character string that specifies the part of the key used for hashing. Eg "{}" or "$$". <a href="notes/recommendation.md#hash-tags">Hash tag</a>  enable mapping different keys to the same server as long as the part of the key within the tag is the same.</li>
<li>
<strong>distribution</strong>: The key distribution mode. Possible values are:

<ul class="task-list">
<li>ketama</li>
<li>modula</li>
<li>random</li>
</ul>
</li>
<li>
<strong>timeout</strong>: The timeout value in msec that we wait for to establish a connection to the server or receive a response from a server. By default, we wait indefinitely.</li>
<li>
<strong>backlog</strong>: The TCP backlog argument. Defaults to 512.</li>
<li>
<strong>preconnect</strong>: A boolean value that controls if nutcracker should preconnect to all the servers in this pool on process start. Defaults to false.</li>
<li>
<strong>redis</strong>: A boolean value that controls if a server pool speaks redis or memcached protocol. Defaults to false.</li>
<li>
<strong>server_connections</strong>: The maximum number of connections that can be opened to each server. By default, we open at most 1 server connection.</li>
<li>
<strong>auto_eject_hosts</strong>: A boolean value that controls if server should be ejected temporarily when it fails consecutively server_failure_limit times. See <a href="notes/recommendation.md#liveness">liveness recommendations</a> for information. Defaults to false.</li>
<li>
<strong>server_retry_timeout</strong>: The timeout value in msec to wait for before retrying on a temporarily ejected server, when auto_eject_host is set to true. Defaults to 30000 msec.</li>
<li>
<strong>server_failure_limit</strong>: The number of consecutive failures on a server that would lead to it being temporarily ejected when auto_eject_host is set to true. Defaults to 2.</li>
<li>
<strong>servers</strong>: A list of server address, port and weight (name:port:weight or ip:port:weight) for this server pool.</li>
</ul><p>For example, the configuration file in <a href="conf/nutcracker.yml">conf/nutcracker.yml</a>, also shown below, configures 5 server pools with names - <em>alpha</em>, <em>beta</em>, <em>gamma</em>, <em>delta</em> and omega. Clients that intend to send requests to one of the 10 servers in pool delta connect to port 22124 on 127.0.0.1. Clients that intend to send request to one of 2 servers in pool omega connect to unix path /tmp/gamma. Requests sent to pool alpha and omega have no timeout and might require timeout functionality to be implemented on the client side. On the other hand, requests sent to pool beta, gamma and delta timeout after 400 msec, 400 msec and 100 msec respectively when no response is received from the server. Of the 5 server pools, only pools alpha, gamma and delta are configured to use server ejection and hence are resilient to server failures. All the 5 server pools use ketama consistent hashing for key distribution with the key hasher for pools alpha, beta, gamma and delta set to fnv1a_64 while that for pool omega set to hsieh. Also only pool beta uses <a href="notes/recommendation.md#node-names-for-consistent-hashing">nodes names</a> for consistent hashing, while pool alpha, gamma, delta and omega use 'host:port:weight' for consistent hashing. Finally, only pool alpha and beta can speak redis protocol, while pool gamma, deta and omega speak memcached protocol.</p>

<pre><code>alpha:
  listen: 127.0.0.1:22121
  hash: fnv1a_64
  distribution: ketama
  auto_eject_hosts: true
  redis: true
  server_retry_timeout: 2000
  server_failure_limit: 1
  servers:
   - 127.0.0.1:6379:1

beta:
  listen: 127.0.0.1:22122
  hash: fnv1a_64
  hash_tag: "{}"
  distribution: ketama
  auto_eject_hosts: false
  timeout: 400
  redis: true
  servers:
   - 127.0.0.1:6380:1 server1
   - 127.0.0.1:6381:1 server2
   - 127.0.0.1:6382:1 server3
   - 127.0.0.1:6383:1 server4

gamma:
  listen: 127.0.0.1:22123
  hash: fnv1a_64
  distribution: ketama
  timeout: 400
  backlog: 1024
  preconnect: true
  auto_eject_hosts: true
  server_retry_timeout: 2000
  server_failure_limit: 3
  servers:
   - 127.0.0.1:11212:1
   - 127.0.0.1:11213:1

delta:
  listen: 127.0.0.1:22124
  hash: fnv1a_64
  distribution: ketama
  timeout: 100
  auto_eject_hosts: true
  server_retry_timeout: 2000
  server_failure_limit: 1
  servers:
   - 127.0.0.1:11214:1
   - 127.0.0.1:11215:1
   - 127.0.0.1:11216:1
   - 127.0.0.1:11217:1
   - 127.0.0.1:11218:1
   - 127.0.0.1:11219:1
   - 127.0.0.1:11220:1
   - 127.0.0.1:11221:1
   - 127.0.0.1:11222:1
   - 127.0.0.1:11223:1

omega:
  listen: /tmp/gamma
  hash: hsieh
  distribution: ketama
  auto_eject_hosts: false
  servers:
   - 127.0.0.1:11214:100000
   - 127.0.0.1:11215:1
</code></pre>

<p>Finally, to make writing syntactically correct configuration file easier, nutcracker provides a command-line argument -t or --test-conf that can be used to test the YAML configuration file for any syntax error.</p>

<h2>
<a name="user-content-observability" class="anchor" href="#observability" aria-hidden="true"><span class="octicon octicon-link"></span></a>Observability</h2>

<p>Observability in nutcracker is through logs and stats.</p>

<p>Nutcracker exposes stats at the granularity of server pool and servers per pool through the stats monitoring port. The stats are essentially JSON formatted key-value pairs, with the keys corresponding to counter names. By default stats are exposed on port 22222 and aggregated every 30 seconds. Both these values can be configured on program start using the -c or --conf-file and -i or --stats-interval command-line arguments respectively. You can print the description of all stats exported by nutcracker using the -D or --describe-stats command-line argument.</p>

<pre><code>$ nutcracker --describe-stats

pool stats:
  client_eof          "# eof on client connections"
  client_err          "# errors on client connections"
  client_connections  "# active client connections"
  server_ejects       "# times backend server was ejected"
  forward_error       "# times we encountered a forwarding error"
  fragments           "# fragments created from a multi-vector request"

server stats:
  server_eof          "# eof on server connections"
  server_err          "# errors on server connections"
  server_timedout     "# timeouts on server connections"
  server_connections  "# active server connections"
  requests            "# requests"
  request_bytes       "total request bytes"
  responses           "# responses"
  response_bytes      "total response bytes"
  in_queue            "# requests in incoming queue"
  in_queue_bytes      "current request bytes in incoming queue"
  out_queue           "# requests in outgoing queue"
  out_queue_bytes     "current request bytes in outgoing queue"
</code></pre>

<p>Logging in nutcracker is only available when nutcracker is built with logging enabled. By default logs are written to stderr. Nutcracker can also be configured to write logs to a specific file through the -o or --output command-line argument. On a running nutcracker, we can turn log levels up and down by sending it SIGTTIN and SIGTTOU signals respectively and reopen log files by sending it SIGHUP signal.</p>

<h2>
<a name="user-content-pipelining" class="anchor" href="#pipelining" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pipelining</h2>

<p>Nutcracker enables proxying multiple client connections onto one or few server connections. This architectural setup makes it ideal for pipelining requests and responses and hence saving on the round trip time.</p>

<p>For example, if nutcracker is proxying three client connections onto a single server and we get requests - 'get key\r\n', 'set key 0 0 3\r\nval\r\n' and 'delete key\r\n' on these three connections respectively, nutcracker would try to batch these requests and send them as a single message onto the server connection as 'get key\r\nset key 0 0 3\r\nval\r\ndelete key\r\n'.</p>

<p>Pipelining is the reason why nutcracker ends up doing better in terms of throughput even though it introduces an extra hop between the client and server.</p>

<h2>
<a name="user-content-deployment" class="anchor" href="#deployment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deployment</h2>

<p>If you are deploying nutcracker in production, you might consider reading through the <a href="notes/recommendation.md">recommendation document</a> to understand the parameters you could tune in nutcracker to run it efficiently in the production environment.</p>

<h2>
<a name="user-content-utils" class="anchor" href="#utils" aria-hidden="true"><span class="octicon octicon-link"></span></a>Utils</h2>

<ul class="task-list">
<li><a href="https://github.com/wanelo/nagios-checks/blob/master/check_twemproxy">nagios checks</a></li>
<li><a href="https://github.com/wanelo-chef/nad-checks/blob/master/recipes/twemproxy.rb">circunous</a></li>
<li><a href="https://github.com/wuakitv/puppet-twemproxy">puppet module</a></li>
<li><a href="https://github.com/kontera-technologies/nutcracker-web">nutcracker-web</a></li>
<li><a href="https://github.com/eveiga/contrib/tree/nutcracker/plugins/nutcracker">munin-plugin</a></li>
<li><a href="https://github.com/bewie/collectd-twemproxy">collectd-plugin</a></li>
<li><a href="https://github.com/Stono/redis-twemproxy-agent">redis-twemproxy agent</a></li>
<li><a href="https://github.com/sensu/sensu-community-plugins/blob/master/plugins/twemproxy/twemproxy-metrics.rb">sensu-metrics</a></li>
<li><a href="https://github.com/idning/redis-mgr">redis-mgr</a></li>
<li><a href="https://github.com/areina/smitty">smitty for twemproxy failover</a></li>
</ul><h2>
<a name="user-content-users" class="anchor" href="#users" aria-hidden="true"><span class="octicon octicon-link"></span></a>Users</h2>

<ul class="task-list">
<li><a href="http://pinterest.com/">Pinterest</a></li>
<li><a href="https://www.tumblr.com/">Tumblr</a></li>
<li><a href="https://twitter.com/">Twitter</a></li>
<li><a href="http://vine.co/">Vine</a></li>
<li><a href="http://www.kiip.me/">Kiip</a></li>
<li><a href="https://wuaki.tv/">Wuaki.tv</a></li>
<li><a href="http://wanelo.com/">Wanelo</a></li>
<li><a href="http://kontera.com/">Kontera</a></li>
<li><a href="http://www.wikimedia.org/">Wikimedia</a></li>
<li><a href="http://www.bright.com/">Bright</a></li>
<li><a href="http://www.56.com/">56.com</a></li>
<li><a href="http://www.snapchat.com/">Snapchat</a></li>
<li><a href="http://digg.com/">Digg</a></li>
<li><a href="http://advertising.gawker.com/">Gawkermedia</a></li>
<li><a href="http://3scale.net">3scale.net</a></li>
<li><a href="http://www.ooyala.com">Ooyala</a></li>
<li><a href="http://twitch.tv">Twitch</a></li>
</ul><h2>
<a name="user-content-issues-and-support" class="anchor" href="#issues-and-support" aria-hidden="true"><span class="octicon octicon-link"></span></a>Issues and Support</h2>

<p>Have a bug or a question? Please create an issue here on GitHub!</p>

<p><a href="https://github.com/twitter/twemproxy/issues">https://github.com/twitter/twemproxy/issues</a></p>

<h2>
<a name="user-content-committers" class="anchor" href="#committers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Committers</h2>

<ul class="task-list">
<li>Manju Rajashekhar (<a href="https://twitter.com/manju">@manju</a>)</li>
<li>Lin Yang (<a href="https://github.com/idning">@idning</a>)</li>
</ul><p>Thank you to all of our <a href="https://github.com/twitter/twemproxy/graphs/contributors">contributors</a>!</p>

<h2>
<a name="user-content-license" class="anchor" href="#license" aria-hidden="true"><span class="octicon octicon-link"></span></a>License</h2>

<p>Copyright 2012 Twitter, Inc.</p>

<p>Licensed under the Apache License, Version 2.0: <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p></article></div>