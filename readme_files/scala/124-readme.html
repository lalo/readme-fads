<div class="announce instapaper_body md" data-path="README.md" id="readme"><article class="markdown-body entry-content" itemprop="mainContentOfPage"><h1>
<a name="user-content-factorie" class="anchor" href="#factorie" aria-hidden="true"><span class="octicon octicon-link"></span></a>FACTORIE</h1>

<p>This directory contains the source of FACTORIE, a toolkit for probabilistic modeling based on imperatively-defined factor graphs. More information, see <a href="http://factorie.cs.umass.edu">the FACTORIE webpage</a>.</p>

<h2>
<a name="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation</h2>

<p>Installation relies on Maven, version 3.  If you don't already have maven, install it from <a href="http://maven.apache.org/download.html">http://maven.apache.org/download.html</a>.
Alternatively, you can use <a href="http://scala-sbt.org">sbt</a> as outlined below (a script for running sbt comes bundled with Factorie).</p>

<p>To compile type</p>

<pre><code>$ mvn compile
</code></pre>

<p>To accomplish the same with sbt, type</p>

<pre><code>$ ./sbt compile
</code></pre>

<p>You might need additional memory for sbt, if so type</p>

<pre><code>export SBT_OPTS=-Xmx1g
</code></pre>

<p>To create a self-contained .jar, that contains FACTORIE plus all its dependencies, including the Scala runtime, type </p>

<pre><code>$ mvn -Dmaven.test.skip=true package -Pjar-with-dependencies
</code></pre>

<p>To accomplish the same with sbt, type</p>

<pre><code>$ ./sbt assembly
</code></pre>

<p>To create a similar self-contained .jar that also contains all resources needed for NLP (including our lexicons and pre-trained model parameters), type  </p>

<pre><code>$ mvn -Dmaven.test.skip=true package -Pnlp-jar-with-dependencies
</code></pre>

<p>To accomplish the same with sbt, type</p>

<pre><code>$ ./sbt -J-Xmx2G with-nlp-resources:assembly

</code></pre>

<h2>
<a name="user-content-try-out-a-simple-example" class="anchor" href="#try-out-a-simple-example" aria-hidden="true"><span class="octicon octicon-link"></span></a>Try out a simple example</h2>

<p>To get an idea what a simple FACTORIE program might look like, open one of the class files in the tutorial package</p>

<pre><code>$ ls src/main/scala/cc/factorie/tutorial
</code></pre>

<p>To run one of these examples using maven type</p>

<pre><code>$ mvn scala:run -DmainClass=cc.factorie.tutorial.Grid
</code></pre>

<h2>
<a name="user-content-try-out-implemented-nlp-models" class="anchor" href="#try-out-implemented-nlp-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Try out implemented NLP models</h2>

<p>Then you can run some FACTORIE tools from the command-line. For example, you can run many natural language processing tools.</p>

<pre><code>$ bin/fac nlp --wsj-forward-pos --conll-chain-ner
</code></pre>

<p>will launch an NLP server that will perform part-of-speech tagging and named entity recognition in its input.  The server listens for text on a socket, and spawns a parallel document processor on each request.  To feed it input, type in a separate shell</p>

<pre><code>$ echo "I told Mr. Smith to take a job at IBM in Raleigh." | nc localhost 3228
</code></pre>

<p>You can also run a latent Dirichlet allocation (LDA) topic model. Assume that "mytextdir" is a directory name containing many plain text documents each in its own file.  Then typing </p>

<pre><code>$ bin/fac lda --read-dirs mytextdir --num-topics 20 --num-iterations 100
</code></pre>

<p>will run 100 iterations of a sparse collapsed Gibbs sampling on all the documents, and print out the results every 10 iterations. FACTORIE's LDA implementation is faster than MALLET's.</p>

<p>You can also train a document classifier. Assume that "sportsdir" and "politicsdir" are each directories that  contain plan text files in the categories sports and politics. Typing</p>

<pre><code>$ bin/fac classify --read-text-dirs sportsdir politicsdir --write-classifier mymodel.factorie
</code></pre>

<p>will train a log-linear by maximum likelihood (MaxEnt) and save it in the file "mymodel.factorie".</p>

<p>The above are simply a few simple command-line options.  Internally the FACTORIE library contains extensive and general facilities for factor graphs: data representation, model structure, inference, learning.</p></article></div>